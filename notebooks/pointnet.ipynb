{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c259242-8cf8-46f9-a2b2-3de5c1c684ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T21:54:04.979457Z",
     "iopub.status.busy": "2022-06-07T21:54:04.979457Z",
     "iopub.status.idle": "2022-06-07T21:54:07.134537Z",
     "shell.execute_reply": "2022-06-07T21:54:07.133503Z",
     "shell.execute_reply.started": "2022-06-07T21:54:04.979457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import laspy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "def read_las(pointcloudfile, get_attributes=False, useevery=1):\n",
    "    \"\"\"\n",
    "    :param pointcloudfile: specification of input file (format: las or laz)\n",
    "    :param get_attributes: if True, will return all attributes in file, otherwise will only return XYZ (default is False)\n",
    "    :param useevery: value specifies every n-th point to use from input, i.e. simple subsampling (default is 1, i.e. returning every point)\n",
    "    :return: 3D array of points (x,y,z) of length number of points in input file (or subsampled by 'useevery')\n",
    "    \"\"\"\n",
    "\n",
    "    # Read file\n",
    "    inFile = laspy.read(pointcloudfile)\n",
    "\n",
    "    # Get coordinates (XYZ)\n",
    "    coords = np.vstack((inFile.x, inFile.y, inFile.z)).transpose()\n",
    "    coords = coords[::useevery, :]\n",
    "\n",
    "    # Return coordinates only\n",
    "    if get_attributes == False:\n",
    "        return coords\n",
    "\n",
    "    # Return coordinates and attributes\n",
    "    else:\n",
    "        las_fields = [info.name for info in inFile.points.point_format.dimensions]\n",
    "        attributes = {}\n",
    "        for las_field in las_fields[3:]:  # skip the X,Y,Z fields\n",
    "            attributes[las_field] = inFile.points[las_field][::useevery]\n",
    "        return (coords, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02c55e2-30e7-443d-8b0f-1e6659164144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T21:54:07.153419Z",
     "iopub.status.busy": "2022-06-07T21:54:07.153419Z",
     "iopub.status.idle": "2022-06-07T21:54:07.182328Z",
     "shell.execute_reply": "2022-06-07T21:54:07.181292Z",
     "shell.execute_reply.started": "2022-06-07T21:54:07.153419Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PointCloudsInFiles(InMemoryDataset):\n",
    "    \"\"\"Point cloud dataset where one data point is a file.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root_dir, glob=\"*\", column_name=\"\", max_points=200_000, use_columns=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with the datasets\n",
    "            glob (string): Glob string passed to pathlib.Path.glob\n",
    "            column_name (string): Column name to use as target variable (e.g. \"Classification\")\n",
    "            use_columns (list[string]): Column names to add as additional input\n",
    "        \"\"\"\n",
    "        self.files = list(Path(root_dir).glob(glob))\n",
    "        self.column_name = column_name\n",
    "        self.max_points = max_points\n",
    "        if use_columns is None:\n",
    "            use_columns = []\n",
    "        self.use_columns = use_columns\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        filename = str(self.files[idx])\n",
    "        coords, attrs = read_las(filename, get_attributes=True)\n",
    "        if coords.shape[0] >= self.max_points:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=False)\n",
    "        else:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=True)\n",
    "        if len(self.use_columns) > 0:\n",
    "            x = np.empty((self.max_points, len(self.use_columns)), np.float32)\n",
    "            for eix, entry in enumerate(self.use_columns):\n",
    "                x[:, eix] = attrs[entry][use_idx]\n",
    "        else:\n",
    "            x = coords[use_idx, :]\n",
    "        coords = coords - np.mean(coords, axis=0)  # centralize coordinates\n",
    "\n",
    "        # impute target\n",
    "        target = attrs[self.column_name]\n",
    "        target[np.isnan(target)] = np.nanmean(target)\n",
    "\n",
    "        sample = Data(\n",
    "            x=torch.from_numpy(x).float(),\n",
    "            y=torch.from_numpy(\n",
    "                np.unique(np.array(target[use_idx][:, np.newaxis]))\n",
    "            ).type(torch.LongTensor),\n",
    "            pos=torch.from_numpy(coords[use_idx, :]).float(),\n",
    "        )\n",
    "        if coords.shape[0] < 100:\n",
    "            return None\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbd607-ba32-40cf-b624-fbc838e1b349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820c8559-06a3-45a8-8235-80cced0b421c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T21:54:07.186269Z",
     "iopub.status.busy": "2022-06-07T21:54:07.186269Z",
     "iopub.status.idle": "2022-06-07T21:54:07.516478Z",
     "shell.execute_reply": "2022-06-07T21:54:07.515484Z",
     "shell.execute_reply.started": "2022-06-07T21:54:07.186269Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import PointNetConv, global_max_pool\n",
    "\n",
    "\n",
    "class PointNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features,\n",
    "        emb_dims=1024,\n",
    "        use_bn=False,\n",
    "        global_feat=True,\n",
    "    ):\n",
    "        # emb_dims: Embedding Dimensions for PointNet.\n",
    "        super(PointNet, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.num_features = num_features\n",
    "        self.emb_dims = emb_dims\n",
    "        self.use_bn = use_bn\n",
    "        self.global_feat = global_feat\n",
    "        if not self.global_feat:\n",
    "            self.pooling = global_max_pool()\n",
    "\n",
    "        self.layers = self.create_structure()\n",
    "\n",
    "    def create_structure(self):\n",
    "        # PointNet architecture\n",
    "        # self.conv1 = torch.nn.Conv1d(3 + self.num_features, 64, 1)\n",
    "        self.conv1 = PointNetConv(3 + self.num_features, 64, 1)\n",
    "        self.conv2 = PointNetConv(64, 64, 1)\n",
    "        self.conv3 = PointNetConv(64, 64, 1)\n",
    "        self.conv4 = PointNetConv(64, 128, 1)\n",
    "        self.conv5 = PointNetConv(128, self.emb_dims, 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        # If using batch normalization\n",
    "        if self.use_bn:\n",
    "            self.bn1 = torch.nn.BatchNorm1d(64)\n",
    "            self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "            self.bn3 = torch.nn.BatchNorm1d(64)\n",
    "            self.bn4 = torch.nn.BatchNorm1d(128)\n",
    "            self.bn5 = torch.nn.BatchNorm1d(self.emb_dims)\n",
    "\n",
    "        # Set up arcitecture\n",
    "        if self.use_bn:  # if using batch normalization\n",
    "            layers = [\n",
    "                self.conv1,\n",
    "                self.bn1,\n",
    "                self.relu,\n",
    "                self.conv2,\n",
    "                self.bn2,\n",
    "                self.relu,\n",
    "                self.conv3,\n",
    "                self.bn3,\n",
    "                self.relu,\n",
    "                self.conv4,\n",
    "                self.bn4,\n",
    "                self.relu,\n",
    "                self.conv5,\n",
    "                self.bn5,\n",
    "                self.relu,\n",
    "            ]\n",
    "\n",
    "        else:  # if not using batch normalization\n",
    "            layers = [\n",
    "                self.conv1,\n",
    "                self.relu,\n",
    "                self.conv2,\n",
    "                self.relu,\n",
    "                self.conv3,\n",
    "                self.relu,\n",
    "                self.conv4,\n",
    "                self.relu,\n",
    "                self.conv5,\n",
    "                self.relu,\n",
    "            ]\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # output: PointNet Features (Batch x emb_dims)\n",
    "        num_points = input_data.x.shape[0]\n",
    "\n",
    "        if input_data.x.shape[1] != 3:\n",
    "            raise RuntimeError(\"Shape of x must be [NumInPoints x 3]\")\n",
    "\n",
    "        # Create output\n",
    "        x, pos, batch = input_data.x, input_data.pos, input_data.batch\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x = layer(x, pos, batch)\n",
    "            if idx == 1 and not self.global_feat:\n",
    "                point_feature = x\n",
    "\n",
    "        if self.global_feat:\n",
    "            return x\n",
    "        else:\n",
    "            output = self.pooling(x, batch)\n",
    "            output = output.view(1, self.emb_dims, 1).repeat(1, 1, num_points)\n",
    "            return torch.cat([x, point_feature], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c1861d-db3f-4f0a-bbd7-b3e9fe95c440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T21:54:07.518433Z",
     "iopub.status.busy": "2022-06-07T21:54:07.517436Z",
     "iopub.status.idle": "2022-06-07T21:54:07.532372Z",
     "shell.execute_reply": "2022-06-07T21:54:07.531377Z",
     "shell.execute_reply.started": "2022-06-07T21:54:07.518433Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_model, num_classes=40):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.feature_model = feature_model\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(self.feature_model.emb_dims, 512)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(512)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.7)\n",
    "        self.linear2 = torch.nn.Linear(512, 256)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(256)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.7)\n",
    "        self.linear3 = torch.nn.Linear(256, self.num_classes)\n",
    "\n",
    "        self.pooling = global_max_pool\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        output = self.pooling(self.feature_model(input_data))\n",
    "        output = F.relu(self.bn1(self.linear1(output)))\n",
    "        output = self.dropout1(output)\n",
    "        output = F.relu(self.bn2(self.linear2(output)))\n",
    "        output = self.dropout2(output)\n",
    "        output = self.linear3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38564732-2d44-4e4f-82ea-952287a9231a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T21:54:07.645867Z",
     "iopub.status.busy": "2022-06-07T21:54:07.645867Z",
     "iopub.status.idle": "2022-06-07T21:54:07.690673Z",
     "shell.execute_reply": "2022-06-07T21:54:07.689677Z",
     "shell.execute_reply.started": "2022-06-07T21:54:07.645867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1bb884-4fb6-4528-8201-d32f7145271d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T21:54:08.273809Z",
     "iopub.status.busy": "2022-06-07T21:54:08.272845Z",
     "iopub.status.idle": "2022-06-07T21:54:08.292725Z",
     "shell.execute_reply": "2022-06-07T21:54:08.291774Z",
     "shell.execute_reply.started": "2022-06-07T21:54:08.273809Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IOStream:\n",
    "    def __init__(self, path):\n",
    "        self.f = open(path, \"a\")\n",
    "\n",
    "    def cprint(self, text):\n",
    "        print(text)\n",
    "        self.f.write(text + \"\\n\")\n",
    "        self.f.flush\n",
    "\n",
    "    def close(self):\n",
    "        sefl.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c61b46-8564-4d72-84bb-a1951b3ec747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T21:54:38.762761Z",
     "iopub.status.busy": "2022-06-07T21:54:38.761765Z",
     "iopub.status.idle": "2022-06-07T21:54:38.784665Z",
     "shell.execute_reply": "2022-06-07T21:54:38.783670Z",
     "shell.execute_reply.started": "2022-06-07T21:54:38.762761Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _init_(model_name):\n",
    "    if not os.path.exists(\"checkpoints\"):\n",
    "        os.makedirs(\"checkpoints\")\n",
    "    if not os.path.exists(\"checkpoints/\" + model_name):\n",
    "        os.makedirs(\"checkpoints/\" + model_name)\n",
    "    if not os.path.exists(\"checkpoints/\" + model_name + \"/models\"):\n",
    "        os.makedirs(\"checkpoints/\" + model_name + \"/models\")\n",
    "\n",
    "\n",
    "def test_one_epoch(device, model, test_loader):\n",
    "    model.eval()  # https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch\n",
    "    test_loss = 0.0\n",
    "    pred = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for i, data in enumerate(tqdm(test_loader)):\n",
    "        data.to(device)\n",
    "\n",
    "        # Call model\n",
    "        output = model(data)\n",
    "\n",
    "        # Define validation loss using negative log likelihood loss and softmax\n",
    "        loss_val = torch.nn.funcitonal.nll_loss(\n",
    "            torch.nn.functional.log_softmax(output, dim=1), target, size_average=False\n",
    "        )\n",
    "\n",
    "        # Update test_lost and count\n",
    "        test_loss += loss_val.item()\n",
    "        count += output.size(0)\n",
    "\n",
    "        # Update pred\n",
    "        _, pred1 = output.max(dim=1)\n",
    "        ag = pred1 == target\n",
    "        am = ag.sum()\n",
    "        pred += am.item()\n",
    "\n",
    "    # Calculate test_loss and accuracy\n",
    "    test_loss = float(test_loss) / count\n",
    "    accuracy = float(pred) / count\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def test(device, model, test_loader, textio):\n",
    "    test_loss, test_accuracy = test_one_epoch(device, model, test_loader)\n",
    "    textio.cprint(\n",
    "        \"Validation Loss: %f & Validation Accuracy: %f\" % (test_loss, test_accuracy)\n",
    "    )\n",
    "\n",
    "\n",
    "def train_one_epoch(device, model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    pred = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        # Send data to device\n",
    "        data.to(device)\n",
    "\n",
    "        # Call model\n",
    "        output = model(data)\n",
    "\n",
    "        # Define validation loss using negative log likelihood loss and softmax\n",
    "        loss_val = torch.nn.funcitonal.nll_loss(\n",
    "            torch.nn.functional.log_softmax(output, dim=1), target, size_average=False\n",
    "        )\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update train_loss and count\n",
    "        train_loss += loss_val.item()\n",
    "        count += output.size(0)\n",
    "\n",
    "        # Update pred\n",
    "        _, pred1 = output.max(dim=1)\n",
    "        ag = pred1 == target\n",
    "        am = ag.sum()\n",
    "        pred += am.item()\n",
    "\n",
    "    # Calculate train_loss and accuracy\n",
    "    train_loss = float(train_loss) / count\n",
    "    accuracy = float(pred) / count\n",
    "\n",
    "    return train_loss, accuracy\n",
    "\n",
    "\n",
    "def train(\n",
    "    device,\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    boardio,\n",
    "    textio,\n",
    "    checkpoint,\n",
    "    optimizer=\"Adam\",\n",
    "    start_epoch=0,\n",
    "    epochs=200,\n",
    "):\n",
    "    # Set up optimizer\n",
    "    learnable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    if optimizer == \"Adam\":  # Adam optimizer\n",
    "        optimizer = torch.optim.Adam(learnable_params)\n",
    "    else:  # SGD optimizer\n",
    "        optimizer = torch.optim.SGD(learnable_params, lr=0.1)\n",
    "\n",
    "    # Set up checkpoint\n",
    "    if checkpoint is not None:\n",
    "        min_loss = checkpoint[\"min_loss\"]\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # Define best_test_loss\n",
    "    best_test_los = np.inf\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        # Train Model\n",
    "        train_loss, train_accuracy = train_one_epoch(\n",
    "            device, model, train_loader, optimizer\n",
    "        )\n",
    "\n",
    "        # Test Model\n",
    "        test_loss, test_accuracy = test_one_epoch(device, model, test_loader)\n",
    "\n",
    "        # Save Best Model\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_lloss = test_loss\n",
    "            snap = {\n",
    "                # state_dict: https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"min_loss\": best_test_loss,\n",
    "                \"optimizer\": optimizer.state_dict,\n",
    "            }\n",
    "            torch.save(snap, f\"checkpoints/{model_name}/models/best_model_snap.t7\")\n",
    "            torch.save(\n",
    "                model.state_dict, f\"checkpoints/{model_name}/models/best_model.t7\"\n",
    "            )\n",
    "            torch.save(\n",
    "                model.feature_model.state_dict(),\n",
    "                f\"checkpoitns/{model_name}/models/best_ptnet_model.t7\",\n",
    "            )\n",
    "\n",
    "        # Save model\n",
    "        torch.save(snap, f\"checkpoints/{model_name}/models/model_snap.t7\")\n",
    "        torch.save(model.state_dict, f\"checkpoints/{model_name}/models/model.t7\")\n",
    "        torch.save(\n",
    "            model.feature_model.state_dict(),\n",
    "            f\"checkpoitns/{model_name}/models/ptnet_model.t7\",\n",
    "        )\n",
    "\n",
    "        boardio.add_scalar(\"Train Loss\", train_loss, epoch + 1)\n",
    "        boardio.add_scalar(\"Test Loss\", test_loss, epoch + 1)\n",
    "        boardio.add_scalar(\"Best Test Loss\", best_test_loss, epoch + 1)\n",
    "        boardio.add_scalar(\"Train Accuracy\", train_accuracy, epoch + 1)\n",
    "        boardio.add_scalar(\"Test Accuracy\", test_accuracy, epoch + 1)\n",
    "\n",
    "        textio.cprint(\n",
    "            \"EPOCH:: %d, Training Loss: %f, Testing Loss: %f, Best Loss: %f\"\n",
    "            % (epoch + 1, train_loss, test_loss, best_test_loss)\n",
    "        )\n",
    "        textio.cprint(\n",
    "            \"EPOCH:: %d, Training Accuracy: %f Testing Accuracy: %f\"\n",
    "            % (epoch + 1, train_accuracy, test_accuracy)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5edeb9e-2de1-49c7-b882-7f370b3f799e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T21:54:40.034844Z",
     "iopub.status.busy": "2022-06-07T21:54:40.034844Z",
     "iopub.status.idle": "2022-06-07T21:54:40.058705Z",
     "shell.execute_reply": "2022-06-07T21:54:40.057710Z",
     "shell.execute_reply.started": "2022-06-07T21:54:40.034844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_dataset_path = r\"D:\\MurrayBrent\\git\\point-dl\\input\\train\"\n",
    "    test_dataset_path = r\"D:\\MurrayBrent\\git\\point-dl\\input\\test\"\n",
    "    model_name = \"PointNet\"\n",
    "    use_columns = []\n",
    "\n",
    "    boardio = SummaryWriter(log_dir=\"checkpoints/\" + model_name)\n",
    "    _init_(model_name)\n",
    "\n",
    "    textio = IOStream(\"checkpoints/\" + model_name + \"/run.log\")\n",
    "    textio.cprint(model_name)\n",
    "\n",
    "    # Get training and test datasets\n",
    "    trainset = PointCloudsInFiles(\n",
    "        train_dataset_path, \"*.laz\", \"Class\", max_points=1024, use_columns=use_columns\n",
    "    )\n",
    "    testset = PointCloudsInFiles(\n",
    "        test_dataset_path, \"*.laz\", \"Class\", max_points=1024, use_columns=use_columns\n",
    "    )\n",
    "\n",
    "    # Load training and test datasets\n",
    "    train_loader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Define device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ptnet = PointNet(num_features=len(use_columns), emb_dims=1024, use_bn=True)\n",
    "    model = Classifier(feature_model=ptnet)\n",
    "\n",
    "    checkpoint = None\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    train(\n",
    "        device=device,\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        boardio=boardio,\n",
    "        textio=textio,\n",
    "        checkpoint=checkpoint,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd27100b-107f-4402-8e52-22ab9a77ba36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T21:54:41.888843Z",
     "iopub.status.busy": "2022-06-07T21:54:41.887848Z",
     "iopub.status.idle": "2022-06-07T21:54:44.936815Z",
     "shell.execute_reply": "2022-06-07T21:54:44.933879Z",
     "shell.execute_reply.started": "2022-06-07T21:54:41.888843Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/12 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 16384 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboardio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboardio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtextio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtextio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(device, model, train_loader, test_loader, boardio, textio, checkpoint, optimizer, start_epoch, epochs)\u001b[0m\n\u001b[0;32m    116\u001b[0m best_test_los \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, epochs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# Train Model\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Test Model\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m test_one_epoch(device, model, test_loader)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(device, model, train_loader, optimizer)\u001b[0m\n\u001b[0;32m     59\u001b[0m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Call model\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Define validation loss using negative log likelihood loss and softmax\u001b[39;00m\n\u001b[0;32m     65\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfuncitonal\u001b[38;5;241m.\u001b[39mnll_loss(\n\u001b[0;32m     66\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlog_softmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), target, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     67\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data):\n\u001b[1;32m---> 18\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m     output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(output)))\n\u001b[0;32m     20\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(output)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mPointNet.forward\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    105\u001b[0m x, pos, batch \u001b[38;5;241m=\u001b[39m input_data\u001b[38;5;241m.\u001b[39mx, input_data\u001b[38;5;241m.\u001b[39mpos, input_data\u001b[38;5;241m.\u001b[39mbatch\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m--> 107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_feat:\n\u001b[0;32m    109\u001b[0m         point_feature \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\conv\\point_conv.py:87\u001b[0m, in \u001b[0;36mPointNetConv.forward\u001b[1;34m(self, x, pos, edge_index)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, Tensor):\n\u001b[0;32m     86\u001b[0m     edge_index, _ \u001b[38;5;241m=\u001b[39m remove_self_loops(edge_index)\n\u001b[1;32m---> 87\u001b[0m     edge_index, _ \u001b[38;5;241m=\u001b[39m \u001b[43madd_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[0;32m     90\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m set_diag(edge_index)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\utils\\loop.py:145\u001b[0m, in \u001b[0;36madd_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill_value\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    143\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_attr, loop_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 145\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 16384 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch Python 3.9",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
