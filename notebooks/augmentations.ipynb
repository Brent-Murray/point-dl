{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c49629-b73f-4725-b0f6-7b011352e087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:21:56.528440Z",
     "iopub.status.busy": "2022-06-16T21:21:56.527445Z",
     "iopub.status.idle": "2022-06-16T21:21:58.815706Z",
     "shell.execute_reply": "2022-06-16T21:21:58.815706Z",
     "shell.execute_reply.started": "2022-06-16T21:21:56.528440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import laspy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7a98a6-ae0c-4793-ab8b-32ffd2399d67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:21:58.815706Z",
     "iopub.status.busy": "2022-06-16T21:21:58.815706Z",
     "iopub.status.idle": "2022-06-16T21:21:58.833136Z",
     "shell.execute_reply": "2022-06-16T21:21:58.831151Z",
     "shell.execute_reply.started": "2022-06-16T21:21:58.815706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_las(pointcloudfile, get_attributes=False, useevery=1):\n",
    "    \"\"\"\n",
    "    :param pointcloudfile: specification of input file (format: las or laz)\n",
    "    :param get_attributes: if True, will return all attributes in file, otherwise will only return XYZ (default is False)\n",
    "    :param useevery: value specifies every n-th point to use from input, i.e. simple subsampling (default is 1, i.e. returning every point)\n",
    "    :return: 3D array of points (x,y,z) of length number of points in input file (or subsampled by 'useevery')\n",
    "    \"\"\"\n",
    "\n",
    "    # Read file\n",
    "    inFile = laspy.read(pointcloudfile)\n",
    "\n",
    "    # Get coordinates (XYZ)\n",
    "    coords = np.vstack((inFile.x, inFile.y, inFile.z)).transpose()\n",
    "    coords = coords[::useevery, :]\n",
    "\n",
    "    # Return coordinates only\n",
    "    if get_attributes == False:\n",
    "        return coords\n",
    "\n",
    "    # Return coordinates and attributes\n",
    "    else:\n",
    "        las_fields = [info.name for info in inFile.points.point_format.dimensions]\n",
    "        attributes = {}\n",
    "        # for las_field in las_fields[3:]:  # skip the X,Y,Z fields\n",
    "        for las_field in las_fields:  # get all fields\n",
    "            attributes[las_field] = inFile.points[las_field][::useevery]\n",
    "        return (coords, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506c7b46-1d6b-41c6-9b86-d6a2216394aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:21:58.836127Z",
     "iopub.status.busy": "2022-06-16T21:21:58.835131Z",
     "iopub.status.idle": "2022-06-16T21:21:58.847079Z",
     "shell.execute_reply": "2022-06-16T21:21:58.846083Z",
     "shell.execute_reply.started": "2022-06-16T21:21:58.836127Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rotate_points(coords):\n",
    "    rotation = np.random.uniform(-180, 180)\n",
    "    # Convert rotation values to radians\n",
    "    rotation = np.radians(rotation)\n",
    "\n",
    "    # Rotate point cloud\n",
    "    rot_mat = np.array(\n",
    "        [\n",
    "            [np.cos(rotation), -np.sin(rotation), 0],\n",
    "            [np.sin(rotation), np.cos(rotation), 0],\n",
    "            [0, 0, 1],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    aug_coords = coords\n",
    "    aug_coords[:, :3] = np.matmul(aug_coords[:, :3], rot_mat)\n",
    "    return aug_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034ea0b5-766e-42e1-a346-a964e05b498d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:21:58.849072Z",
     "iopub.status.busy": "2022-06-16T21:21:58.849072Z",
     "iopub.status.idle": "2022-06-16T21:21:58.863008Z",
     "shell.execute_reply": "2022-06-16T21:21:58.862011Z",
     "shell.execute_reply.started": "2022-06-16T21:21:58.849072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def point_removal(coords, x=None):\n",
    "    # Get list of ids\n",
    "    idx = list(range(np.shape(coords)[0]))\n",
    "    random.shuffle(idx)  # shuffle ids\n",
    "    idx = np.random.choice(\n",
    "        idx, random.randint(round(len(idx) * 0.9), len(idx)), replace=False\n",
    "    )  # pick points randomly removing 0 - 50 points\n",
    "\n",
    "    # Remove random values\n",
    "    aug_coords = coords[idx, :]  # remove coords\n",
    "    if x is None:  # remove x\n",
    "        aug_x = aug_coords\n",
    "    else:\n",
    "        aug_x = x[idx, :]\n",
    "\n",
    "    return aug_coords, aug_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715b4600-7ae0-430f-8e73-4f2530115d7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:21:58.864999Z",
     "iopub.status.busy": "2022-06-16T21:21:58.864003Z",
     "iopub.status.idle": "2022-06-16T21:21:58.878937Z",
     "shell.execute_reply": "2022-06-16T21:21:58.877942Z",
     "shell.execute_reply.started": "2022-06-16T21:21:58.864999Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_noise(coords, dim, x=None):\n",
    "    # Random standard deviation value\n",
    "    random_noise_sd = np.random.uniform(0.01, 0.025)\n",
    "    print(np.shape(x))\n",
    "\n",
    "    # Add/Subtract noise\n",
    "    if np.random.uniform(0, 1) >= 0.5:  # 50% chance to add\n",
    "        aug_coords = coords + np.random.normal(\n",
    "            0, random_noise_sd, size=(np.shape(coords)[0], 3)\n",
    "        )\n",
    "        if x is None:\n",
    "            aug_x = aug_coords\n",
    "        else:\n",
    "            aug_x = x + np.random.normal(0, random_noise_sd, size=(np.shape(x)))\n",
    "    else:  # 50% chance to subtract\n",
    "        aug_coords = coords - np.random.normal(\n",
    "            0, random_noise_sd, size=(np.shape(coords)[0], 3)\n",
    "        )\n",
    "        if x is None:\n",
    "            aug_x = aug_coords\n",
    "        else:\n",
    "            aug_x = x - np.random.normal(0, random_noise_sd, size=(np.shape(x)))\n",
    "\n",
    "    # Randomly choose between 0 and 50 augmented noise points\n",
    "    use_idx = np.random.choice(\n",
    "        aug_coords.shape[0], random.randint(0, round(len(aug_coords) * 0.1)), replace=False\n",
    "    )\n",
    "    aug_coords = aug_coords[use_idx, :]  # get random points\n",
    "    aug_coords = np.append(coords, aug_coords, axis=0)  # add points\n",
    "    aug_x = aug_x[use_idx, :]  # get random point values\n",
    "    aug_x = np.append(x, aug_x)  # add random point values\n",
    "\n",
    "    if dim == 1:\n",
    "        aug_x = aug_x[:, np.newaxis]\n",
    "\n",
    "    return aug_coords, aug_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7351e3cb-2ce0-496c-aebd-0e05b86b3768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:21:58.944648Z",
     "iopub.status.busy": "2022-06-16T21:21:58.944648Z",
     "iopub.status.idle": "2022-06-16T21:21:59.633750Z",
     "shell.execute_reply": "2022-06-16T21:21:59.633750Z",
     "shell.execute_reply.started": "2022-06-16T21:21:58.944648Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_3d(coords):\n",
    "    # Plot parameters\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.00, 7.00]  # figure size\n",
    "    plt.rcParams[\"figure.autolayout\"] = True  # auto layout\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure()  # initialize figure\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")  # 3d projection\n",
    "    x = coords[:, 0]  # x coordinates\n",
    "    y = coords[:, 1]  # y coordinates\n",
    "    z = coords[:, 2]  # z coordinates\n",
    "    ax.scatter(x, y, z, c=z, alpha=1)  # create a scatter plot\n",
    "    plt.show()  # show plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57644714-e5e7-4c01-b98e-3107962cde83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:21:59.633750Z",
     "iopub.status.busy": "2022-06-16T21:21:59.633750Z",
     "iopub.status.idle": "2022-06-16T21:21:59.681637Z",
     "shell.execute_reply": "2022-06-16T21:21:59.680642Z",
     "shell.execute_reply.started": "2022-06-16T21:21:59.633750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PointCloudsInFiles(InMemoryDataset):\n",
    "    \"\"\"Point cloud dataset where one data point is a file.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root_dir, glob=\"*\", column_name=\"\", max_points=200_000, use_columns=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with the datasets\n",
    "            glob (string): Glob string passed to pathlib.Path.glob\n",
    "            column_name (string): Column name to use as target variable (e.g. \"Classification\")\n",
    "            use_columns (list[string]): Column names to add as additional input\n",
    "        \"\"\"\n",
    "        self.files = list(Path(root_dir).glob(glob))\n",
    "        self.column_name = column_name\n",
    "        self.max_points = max_points\n",
    "        if use_columns is None:\n",
    "            use_columns = []\n",
    "        self.use_columns = use_columns\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return length\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Get file name\n",
    "        filename = str(self.files[idx])\n",
    "\n",
    "        # Read las/laz file\n",
    "        coords, attrs = read_las(filename, get_attributes=True)\n",
    "\n",
    "        # Resample number of points to max_points\n",
    "        if coords.shape[0] >= self.max_points:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=False)\n",
    "        else:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=True)\n",
    "\n",
    "        # Get x values\n",
    "        if len(self.use_columns) > 0:\n",
    "            x = np.empty((self.max_points, len(self.use_columns)), np.float32)\n",
    "            for eix, entry in enumerate(self.use_columns):\n",
    "                x[:, eix] = attrs[entry][use_idx]\n",
    "        else:\n",
    "            x = coords[use_idx, :]\n",
    "\n",
    "        # Get coords\n",
    "        coords = coords - np.mean(coords, axis=0)  # centralize coordinates\n",
    "\n",
    "        # impute target\n",
    "        target = attrs[self.column_name]\n",
    "        target[np.isnan(target)] = np.nanmean(target)\n",
    "\n",
    "        # Transform data to tensor\n",
    "        sample = Data(\n",
    "            x=torch.from_numpy(x).float(),\n",
    "            y=torch.from_numpy(\n",
    "                np.unique(np.array(target[use_idx][:, np.newaxis]))\n",
    "            ).type(torch.LongTensor),\n",
    "            pos=torch.from_numpy(coords[use_idx, :]).float(),\n",
    "        )\n",
    "        if coords.shape[0] < 100:\n",
    "            return None\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "634df5b4-0dbc-49cd-a3fd-5951804d3c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:21:59.685620Z",
     "iopub.status.busy": "2022-06-16T21:21:59.684624Z",
     "iopub.status.idle": "2022-06-16T21:21:59.728481Z",
     "shell.execute_reply": "2022-06-16T21:21:59.727481Z",
     "shell.execute_reply.started": "2022-06-16T21:21:59.685620Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AugmentPointCloudsInFiles(InMemoryDataset):\n",
    "    \"\"\"Point cloud dataset where one data point is a file.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root_dir, glob=\"*\", column_name=\"\", max_points=200_000, use_columns=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with the datasets\n",
    "            glob (string): Glob string passed to pathlib.Path.glob\n",
    "            column_name (string): Column name to use as target variable (e.g. \"Classification\")\n",
    "            use_columns (list[string]): Column names to add as additional input\n",
    "        \"\"\"\n",
    "        self.files = list(Path(root_dir).glob(glob))\n",
    "        self.column_name = column_name\n",
    "        self.max_points = max_points\n",
    "        if use_columns is None:\n",
    "            use_columns = []\n",
    "        self.use_columns = use_columns\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return length\n",
    "        return len(self.files)  # NEED TO ADD MULTIPLICATION FOR NUMBER OF AUGMENTS\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Get file name\n",
    "        filename = str(self.files[idx])\n",
    "\n",
    "        # Read las/laz file\n",
    "        coords, attrs = read_las(filename, get_attributes=True)\n",
    "\n",
    "        # Resample number of points to max_points\n",
    "        if coords.shape[0] >= self.max_points:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=False)\n",
    "        else:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=True)\n",
    "\n",
    "        # Get x values\n",
    "        if len(self.use_columns) > 0:\n",
    "            x = np.empty((self.max_points, len(self.use_columns)), np.float32)\n",
    "            for eix, entry in enumerate(self.use_columns):\n",
    "                x[:, eix] = attrs[entry][use_idx]\n",
    "        else:\n",
    "            x = coords[use_idx, :]\n",
    "\n",
    "        # Get coords\n",
    "        coords = coords[use_idx, :]\n",
    "        coords = coords - np.mean(coords, axis=0)  # centralize coordinates\n",
    "\n",
    "        # Augmentation\n",
    "        coords, x = point_removal(coords, x)\n",
    "        coords, x = random_noise(coords, use_columns, x)\n",
    "        coords = rotate_points(coords)\n",
    "\n",
    "        # impute target\n",
    "        target = attrs[self.column_name]\n",
    "        target[np.isnan(target)] = np.nanmean(target)\n",
    "\n",
    "        # Transform data to tensor\n",
    "        sample = Data(\n",
    "            x=torch.from_numpy(x).float(),\n",
    "            y=torch.from_numpy(np.unique(np.array(target[:, np.newaxis]))).type(\n",
    "                torch.LongTensor\n",
    "            ),\n",
    "            pos=torch.from_numpy(coords).float(),\n",
    "        )\n",
    "        if coords.shape[0] < 100:\n",
    "            return None\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "637fe980-3726-4213-8d2f-4ec184fc3662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:22:54.387283Z",
     "iopub.status.busy": "2022-06-16T21:22:54.387283Z",
     "iopub.status.idle": "2022-06-16T21:22:54.398235Z",
     "shell.execute_reply": "2022-06-16T21:22:54.397240Z",
     "shell.execute_reply.started": "2022-06-16T21:22:54.387283Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_path = r\"D:\\MurrayBrent\\data\\RMF_ITD\\PLOT_LAS\\BUF_5M_SC\\train\"\n",
    "max_points = 2048\n",
    "use_columns = [\"intensity\"]\n",
    "\n",
    "if train_dataset_path:\n",
    "    trainset_aug = AugmentPointCloudsInFiles(\n",
    "        train_dataset_path,\n",
    "        \"*.laz\",\n",
    "        \"Class\",\n",
    "        max_points=max_points,\n",
    "        use_columns=use_columns,\n",
    "    )\n",
    "\n",
    "    trainset = PointCloudsInFiles(\n",
    "        train_dataset_path,\n",
    "        \"*.laz\",\n",
    "        \"Class\",\n",
    "        max_points=max_points,\n",
    "        use_columns=use_columns,\n",
    "    )\n",
    "\n",
    "    trainset_con = torch.utils.data.ConcatDataset([trainset, trainset_aug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e85d88e-55c3-4a75-ac0f-0efc15929d21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:22:55.767421Z",
     "iopub.status.busy": "2022-06-16T21:22:55.767421Z",
     "iopub.status.idle": "2022-06-16T21:22:55.783314Z",
     "shell.execute_reply": "2022-06-16T21:22:55.782318Z",
     "shell.execute_reply.started": "2022-06-16T21:22:55.767421Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# train_loader = DataLoader(trainset_con, batch_size=32, shuffle=True, num_workers=0)\n",
    "train_loader = DataLoader(trainset_con, batch_size=32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5755f27d-5bc4-420c-b47c-0512eb54654e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T21:22:57.484650Z",
     "iopub.status.busy": "2022-06-16T21:22:57.484650Z",
     "iopub.status.idle": "2022-06-16T21:23:09.538855Z",
     "shell.execute_reply": "2022-06-16T21:23:09.538855Z",
     "shell.execute_reply.started": "2022-06-16T21:22:57.484650Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[65174, 1], y=[32], pos=[65174, 3], batch=[65174], ptr=[33])\n",
      "DataBatch(x=[64962, 1], y=[32], pos=[64962, 3], batch=[64962], ptr=[33])\n",
      "DataBatch(x=[65189, 1], y=[32], pos=[65189, 3], batch=[65189], ptr=[33])\n",
      "DataBatch(x=[65254, 1], y=[32], pos=[65254, 3], batch=[65254], ptr=[33])\n",
      "DataBatch(x=[65133, 1], y=[32], pos=[65133, 3], batch=[65133], ptr=[33])\n",
      "DataBatch(x=[65104, 1], y=[32], pos=[65104, 3], batch=[65104], ptr=[33])\n",
      "DataBatch(x=[65206, 1], y=[32], pos=[65206, 3], batch=[65206], ptr=[33])\n",
      "DataBatch(x=[65201, 1], y=[32], pos=[65201, 3], batch=[65201], ptr=[33])\n",
      "DataBatch(x=[65149, 1], y=[32], pos=[65149, 3], batch=[65149], ptr=[33])\n",
      "DataBatch(x=[65115, 1], y=[32], pos=[65115, 3], batch=[65115], ptr=[33])\n",
      "DataBatch(x=[60902, 1], y=[30], pos=[60902, 3], batch=[60902], ptr=[31])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecd010-6d52-436c-a833-eea0f03a76cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38de4f-1a0c-4d3a-937d-675296a8006a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch Python 3.9",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
