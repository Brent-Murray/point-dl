{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9579c1f9-846c-496c-a13f-c5c92d4afea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-31T23:08:52.532497Z",
     "iopub.status.busy": "2022-05-31T23:08:52.531503Z",
     "iopub.status.idle": "2022-05-31T23:08:52.544412Z",
     "shell.execute_reply": "2022-05-31T23:08:52.543417Z",
     "shell.execute_reply.started": "2022-05-31T23:08:52.532497Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch import nn\n",
    "from torch_geometric.nn import XConv, fps, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ad2f9-bacb-4173-8c25-78c5989be681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCNN(pl.LightningModule):\n",
    "    def __init__(self, numfeatures=0):\n",
    "        super().__init__()\n",
    "        self.learning_rate = 1e-3  # learning rate\n",
    "        self.train_acc = pl.metrics.Accuracy()  # traning accuracy\n",
    "        self.val_acc = pl.metrics.Accuracy()  # validation accuracy\n",
    "        self.test_acc = pl.metrics.Accuracy()  # test accuracy\n",
    "        self.numfeatures = numfeatures  # number of features\n",
    "\n",
    "        # First XConv layer\n",
    "        self.conv1 = XConv(\n",
    "            self.numfeatures, 48, dim=3, kernel_size=8, hidden_channels=32\n",
    "        )\n",
    "\n",
    "        # Second XConv layer\n",
    "        self.conv2 = XConv(\n",
    "            48, 96, dim=3, kernel_size=12, hidden_channels=64, dilation=2\n",
    "        )\n",
    "\n",
    "        # Third XConv layer\n",
    "        self.conv3 = XConv(\n",
    "            96, 192, dim=3, kernel_size=16, hidden_channels=128, dilation=2\n",
    "        )\n",
    "\n",
    "        # Fourth XConv layer\n",
    "        self.conv4 = XConv(\n",
    "            192, 384, dim=3, kernel_size=16, hidden_channel=256, dilation=2\n",
    "        )\n",
    "\n",
    "        # Multilayer Perceptrons (MLPs) at the end of the PointCNN\n",
    "        self.lin1 = nn.Linear(384, 256)\n",
    "        self.lin2 = nn.Linear(256, 125)\n",
    "        self.lin3 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, batch = data.pos, data.batch\n",
    "        x = data.x if self.numfeatures else None\n",
    "\n",
    "        # First XConv with no features\n",
    "        x = F.relu(self.conv1(x, pos, batch))\n",
    "\n",
    "        # Farthest point sampling, keeping only 37.5%\n",
    "        idx = fps(pos, batch, ratio=0.375)\n",
    "        x, pos, batch = x[idx], pos[idx], batch[idx]\n",
    "\n",
    "        # Second XConv\n",
    "        x = F.relu(self.conv2(x, pos, batch))\n",
    "\n",
    "        # Farthest point samplling, keepiong only 33.4%\n",
    "        idx = fps(pos, batch, ratio=0.334)\n",
    "        x, pos, batch = x[idx], pos[idx], batch[idx]\n",
    "\n",
    "        # Two additional XConvs\n",
    "        x = F.relu(self.conv3(x, pos, batch))\n",
    "        x = F.relu(self.conv4(x, pos, batch))\n",
    "\n",
    "        # Pooling batch-elements together\n",
    "        # Each tree is described in one single point with 384 features\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # MLPs at the end with ReLU\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "\n",
    "        # Dropout: Set randomly to value of zero\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "\n",
    "        # log-SofMax activation to callculate Negative Log Likelihood (NLL)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch Python 3.9",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
