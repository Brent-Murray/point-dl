{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0ea536-d72b-4620-a80c-780037e6964a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:32:50.159561Z",
     "iopub.status.busy": "2022-06-07T15:32:50.159561Z",
     "iopub.status.idle": "2022-06-07T15:32:50.177518Z",
     "shell.execute_reply": "2022-06-07T15:32:50.176516Z",
     "shell.execute_reply.started": "2022-06-07T15:32:50.159561Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import laspy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27afc1f0-5b21-4c10-be55-bb50cb8d75ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:32:51.661663Z",
     "iopub.status.busy": "2022-06-07T15:32:51.661663Z",
     "iopub.status.idle": "2022-06-07T15:32:51.683535Z",
     "shell.execute_reply": "2022-06-07T15:32:51.682538Z",
     "shell.execute_reply.started": "2022-06-07T15:32:51.661663Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_las(pointcloudfile, get_attributes=False, useevery=1):\n",
    "    \"\"\"\n",
    "    :param pointcloudfile: specification of input file (format: las or laz)\n",
    "    :param get_attributes: if True, will return all attributes in file, otherwise will only return XYZ (default is False)\n",
    "    :param useevery: value specifies every n-th point to use from input, i.e. simple subsampling (default is 1, i.e. returning every point)\n",
    "    :return: 3D array of points (x,y,z) of length number of points in input file (or subsampled by 'useevery')\n",
    "    \"\"\"\n",
    "\n",
    "    # Read file\n",
    "    inFile = laspy.read(pointcloudfile)\n",
    "\n",
    "    # Get coordinates (XYZ)\n",
    "    coords = np.vstack((inFile.x, inFile.y, inFile.z)).transpose()\n",
    "    coords = coords[::useevery, :]\n",
    "\n",
    "    # Return coordinates only\n",
    "    if get_attributes == False:\n",
    "        return coords\n",
    "\n",
    "    # Return coordinates and attributes\n",
    "    else:\n",
    "        las_fields = [info.name for info in inFile.points.point_format.dimensions]\n",
    "        attributes = {}\n",
    "        for las_field in las_fields[3:]:  # skip the X,Y,Z fields\n",
    "            attributes[las_field] = inFile.points[las_field][::useevery]\n",
    "        return (coords, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9adbc796-93f0-486f-9ede-826741140bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:32:52.106426Z",
     "iopub.status.busy": "2022-06-07T15:32:52.105430Z",
     "iopub.status.idle": "2022-06-07T15:32:52.123351Z",
     "shell.execute_reply": "2022-06-07T15:32:52.122355Z",
     "shell.execute_reply.started": "2022-06-07T15:32:52.106426Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PointCloudsInFiles(InMemoryDataset):\n",
    "    \"\"\"Point cloud dataset where one data point is a file.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root_dir, glob=\"*\", column_name=\"\", max_points=200_000, use_columns=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with the datasets\n",
    "            glob (string): Glob string passed to pathlib.Path.glob\n",
    "            column_name (string): Column name to use as target variable (e.g. \"Classification\")\n",
    "            use_columns (list[string]): Column names to add as additional input\n",
    "        \"\"\"\n",
    "        self.files = list(Path(root_dir).glob(glob))\n",
    "        self.column_name = column_name\n",
    "        self.max_points = max_points\n",
    "        if use_columns is None:\n",
    "            use_columns = []\n",
    "        self.use_columns = use_columns\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        filename = str(self.files[idx])\n",
    "        coords, attrs = read_las(filename, get_attributes=True)\n",
    "        if coords.shape[0] >= self.max_points:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=False)\n",
    "        else:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=True)\n",
    "        if len(self.use_columns) > 0:\n",
    "            x = np.empty((self.max_points, len(self.use_columns)), np.float32)\n",
    "            for eix, entry in enumerate(self.use_columns):\n",
    "                x[:, eix] = attrs[entry][use_idx]\n",
    "        else:\n",
    "            x = coords[use_idx, :]\n",
    "        coords = coords - np.mean(coords, axis=0)  # centralize coordinates\n",
    "\n",
    "        # impute target\n",
    "        target = attrs[self.column_name]\n",
    "        target[np.isnan(target)] = np.nanmean(target)\n",
    "\n",
    "        sample = Data(\n",
    "            x=torch.from_numpy(x).float(),\n",
    "            y=torch.from_numpy(\n",
    "                np.unique(np.array(target[use_idx][:, np.newaxis]))\n",
    "            ).type(torch.LongTensor),\n",
    "            pos=torch.from_numpy(coords[use_idx, :]).float(),\n",
    "        )\n",
    "        if coords.shape[0] < 100:\n",
    "            return None\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03140555-3e7a-43fa-ac5d-d20a16e50989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:46:34.310644Z",
     "iopub.status.busy": "2022-06-07T15:46:34.310644Z",
     "iopub.status.idle": "2022-06-07T15:46:34.328565Z",
     "shell.execute_reply": "2022-06-07T15:46:34.327569Z",
     "shell.execute_reply.started": "2022-06-07T15:46:34.310644Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = PointCloudsInFiles(\n",
    "    r\"D:\\MurrayBrent\\git\\point-dl\\input\\train\",\n",
    "    \"*.laz\",\n",
    "    \"Class\",\n",
    "    max_points=1024,\n",
    "    # use_columns=[\"intensity\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c47e091-3a29-43f9-8e3e-eead4d7e04ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:46:34.972873Z",
     "iopub.status.busy": "2022-06-07T15:46:34.971909Z",
     "iopub.status.idle": "2022-06-07T15:46:35.003740Z",
     "shell.execute_reply": "2022-06-07T15:46:35.002739Z",
     "shell.execute_reply.started": "2022-06-07T15:46:34.972873Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1024, 3], y=[1], pos=[1024, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c2fc6c-20f7-43a4-a3f3-f8bdea29dcac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:33:22.658103Z",
     "iopub.status.busy": "2022-06-07T15:33:22.658103Z",
     "iopub.status.idle": "2022-06-07T15:33:22.666067Z",
     "shell.execute_reply": "2022-06-07T15:33:22.665072Z",
     "shell.execute_reply.started": "2022-06-07T15:33:22.658103Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0052893c-06c7-4c49-9f90-d23b61fc534f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T15:37:27.057846Z",
     "iopub.status.busy": "2022-06-07T15:37:27.057846Z",
     "iopub.status.idle": "2022-06-07T15:37:27.782731Z",
     "shell.execute_reply": "2022-06-07T15:37:27.780703Z",
     "shell.execute_reply.started": "2022-06-07T15:37:27.057846Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:50\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:70\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:362\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:52\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    print(data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch Python 3.9",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
